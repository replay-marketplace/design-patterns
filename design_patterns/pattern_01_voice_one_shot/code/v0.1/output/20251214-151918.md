# Input Prompt

Okay, so let's make a list of functions. We need some LLM agents. Function number one is message agent. Message agent, okay. For function number one, message agent, you send a text string in Python, and you receive back a text string. Message agent, okay, so it's text to text. Okay, function number two. What is function number two? Okay.


---

# Anthropic Response

# Function List for LLM Agents

## Function 1: âœ“ Message Agent
- **Input:** Text string (Python)
- **Output:** Text string
- **Type:** Text-to-text communication

## Function 2: Options to consider...

Here are some logical next functions for an LLM agent system:

**Option A: Image Agent**
- **Input:** Image file/URL + optional text prompt
- **Output:** Text description or analysis
- **Type:** Image-to-text

**Option B: Tool Agent**
- **Input:** Text string (command/query)
- **Output:** Structured data (JSON/dict) or execution result
- **Type:** Text-to-action (can call external APIs, run code, etc.)

**Option C: Memory Agent**
- **Input:** Text string (query or storage command)
- **Output:** Retrieved memories or confirmation
- **Type:** Text-to-text with persistent storage

**Option D: Router Agent**
- **Input:** Text string (user request)
- **Output:** Routing decision (which agent to call next)
- **Type:** Text-to-metadata

Which direction makes sense for your use case? Or do you have a specific Function 2 in mind?
